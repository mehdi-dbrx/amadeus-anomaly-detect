{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79db8c9b-ca73-436d-ab2a-f1f174421fdf",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769600994561}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Load parquet data and create initial table mc.amadeus2.data"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS mc.amadeus2.data\")\n",
    "df = spark.read.parquet(\"/Volumes/mc/amadeus2/data/part-00000-7118aad9-0739-4860-912f-1a58c85d689c.c000.snappy.parquet\")\n",
    "df.write.saveAsTable(\"mc.amadeus2.data\")\n",
    "display(spark.table(\"mc.amadeus2.data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab36e2e8-15f9-4847-9695-ce34e2d25d7c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Enrich data with origin city and country from IATA lookup"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE mc.amadeus2.data_full_1 AS\n",
    "SELECT\n",
    "  d.*,\n",
    "  i.city AS trip_origin_city_full,\n",
    "  i.country AS trip_origin_country_full\n",
    "FROM mc.amadeus2.data_iata d\n",
    "LEFT JOIN mc.amadeus2.iata i\n",
    "  ON d.trip_origin_city = i.iata\n",
    "\"\"\")\n",
    "display(spark.table(\"mc.amadeus2.data_full_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f98b336-bb36-4bd6-963a-b5916323a5d2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename data_full to data_full_1"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"ALTER TABLE mc.amadeus2.data_full RENAME TO mc.amadeus2.data_full_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "010e2d2e-5c3a-4655-ae37-5826483e585d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Enrich data with destination city and country from IATA lookup"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE mc.amadeus2.data_full AS\n",
    "SELECT\n",
    "  d.*,\n",
    "  i.city AS trip_destination_city_full,\n",
    "  i.country AS trip_destination_country_full\n",
    "FROM mc.amadeus2.data_full_1 d\n",
    "LEFT JOIN mc.amadeus2.iata i\n",
    "  ON d.trip_origin_city = i.iata\n",
    "\"\"\")\n",
    "display(spark.table(\"mc.amadeus2.data_full\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd16b1f0-2a51-44cc-952a-d5f797f5e0b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename data table to data_iata"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"ALTER TABLE mc.amadeus2.data RENAME TO mc.amadeus2.data_iata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa45035-b983-4b84-84ef-cdcda1ed52eb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename data_jan2026 to data_jan26"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"ALTER TABLE mc.amadeus2.data_jan2026 RENAME TO mc.amadeus2.data_jan26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35487288-b52d-4708-8e0b-f651e2f7a134",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Drop IATA table if exists"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS mc.amadeus2.iata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ec9f9f-76d8-4be7-9516-8abc3cee0446",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Drop data_full table if exists"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS mc.amadeus2.data_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5921517a-45b7-4fb5-8cfc-537ce09977b9",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769604383552}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Load IATA codes CSV and create lookup table"
    }
   },
   "outputs": [],
   "source": [
    "df_iata = spark.read.format(\"csv\").option(\"header\", True).load(\"/Volumes/mc/amadeus2/data/iata.csv\")\n",
    "df_iata.write.mode(\"overwrite\").saveAsTable(\"mc.amadeus2.iata\")\n",
    "display(spark.table(\"mc.amadeus2.iata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c86bbc1-2c10-495d-97b7-ca84f01f0bc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query IATA codes for Country"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SELECT * FROM mc.amadeus2.iata WHERE country = 'Ethiopia'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a3f8cb-2de9-45d1-ae2a-d0b7ca347396",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check distinct departure dates in data table"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SELECT DISTINCT flight_leg_departure_date FROM mc.amadeus2.data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e02aac9-8b17-406b-ae39-8b0fe2e7335c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check distinct departure dates in data_jan2026 table"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SELECT DISTINCT flight_leg_departure_date FROM mc.amadeus2.data_jan2026\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e62e085-eae0-4247-82b6-6d1adee26df0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update all departure dates to 2026-01-01"
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "deltaTable = DeltaTable.forName(spark, \"mc.amadeus2.data\")\n",
    "deltaTable.update(\n",
    "    set = { \"flight_leg_departure_date\": \"'2026-01-01'\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc4e796-4b4c-42ac-aa91-082d3955f891",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Expand data across all January 2026 dates using cross join"
    }
   },
   "outputs": [],
   "source": [
    "date_range_df = spark.sql(\"\"\"\n",
    "SELECT explode(sequence(to_date('2026-01-01'), to_date('2026-01-31'), interval 1 day)) AS flight_leg_departure_date\n",
    "\"\"\")\n",
    "\n",
    "df_data = spark.table(\"mc.amadeus2.data\").drop(\"flight_leg_departure_date\")\n",
    "\n",
    "df_expanded = df_data.crossJoin(date_range_df) \\\n",
    "    .withColumn(\"flight_leg_departure_date\", date_range_df[\"flight_leg_departure_date\"])\n",
    "\n",
    "df_expanded.write.mode(\"overwrite\").saveAsTable(\"mc.amadeus2.data_jan2026\")\n",
    "\n",
    "display(spark.table(\"mc.amadeus2.data_jan2026\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ce0758-de82-4daf-abb5-5a6bd3de9b01",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Replace data table with data_full table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE mc.amadeus2.data AS\n",
    "SELECT * FROM mc.amadeus2.data_full\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e3d304d-72d1-4763-bf7b-5f543e1a731f",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769601267449}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT flight_leg_origin_country, COUNT(*) AS count FROM mc.amadeus2.data GROUP BY flight_leg_origin_country ORDER BY flight_leg_origin_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a6c6aad-ba2f-470e-bd97-a711cd58c44a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Aggregate total seats by trip origin and destination"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"\n",
    "SELECT trip_origin_city,\n",
    "       trip_origin_country,\n",
    "       trip_destination_city,\n",
    "       trip_destination_country,\n",
    "       SUM(flight_leg_total_seats) AS total_seats\n",
    "FROM mc.amadeus2.data\n",
    "GROUP BY trip_origin_city,\n",
    "         trip_origin_country,\n",
    "         trip_destination_city,\n",
    "         trip_destination_country\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e82b482-af24-4cb7-82cb-f1638706be28",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769602951250}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Aggregate seats with full city and country names from data_full"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"\n",
    "SELECT trip_origin_city,\n",
    "       trip_origin_city_full,\n",
    "       trip_origin_country,\n",
    "       trip_origin_country_full,\n",
    "       trip_destination_city,\n",
    "       trip_destination_city_full,\n",
    "       trip_destination_country,\n",
    "       trip_destination_country_full,\n",
    "       trip_destination_city,\n",
    "       trip_destination_country,\n",
    "SUM(flight_leg_total_seats) AS total_seats\n",
    "FROM mc.amadeus2.data_full\n",
    "GROUP BY trip_origin_city,\n",
    "         trip_origin_city_full,\n",
    "         trip_origin_country,\n",
    "         trip_origin_country_full,\n",
    "         trip_destination_city,\n",
    "         trip_destination_city_full,\n",
    "         trip_destination_country,\n",
    "         trip_destination_country_full,\n",
    "         trip_destination_city,\n",
    "         trip_destination_country\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb6ab0c1-cc49-4ffd-9674-6175cccf3325",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filter France to Spain routes with full location details"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"\"\"\n",
    "SELECT trip_origin_city,\n",
    "       trip_origin_city_full,\n",
    "       trip_origin_country,\n",
    "       trip_origin_country_full,\n",
    "       trip_destination_city,\n",
    "       trip_destination_city_full,\n",
    "       trip_destination_country,\n",
    "       trip_destination_country_full,\n",
    "       trip_destination_city,\n",
    "       trip_destination_country,\n",
    "SUM(flight_leg_total_seats) AS total_seats\n",
    "FROM mc.amadeus2.data_full\n",
    "WHERE trip_origin_country = 'FR' AND trip_destination_country = 'ES'\n",
    "GROUP BY trip_origin_city,\n",
    "         trip_origin_city_full,\n",
    "         trip_origin_country,\n",
    "         trip_origin_country_full,\n",
    "         trip_destination_city,\n",
    "         trip_destination_city_full,\n",
    "         trip_destination_country,\n",
    "         trip_destination_country_full,\n",
    "         trip_destination_city,\n",
    "         trip_destination_country\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b33376-0b39-432e-85b6-94af0fc03bb7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display data_full table schema"
    }
   },
   "outputs": [],
   "source": [
    "spark.table(\"mc.amadeus2.data_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed7d9ebd-203e-4967-859e-07d368251cfa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Count total rows in data_full table"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"mc.amadeus2.data_full\").selectExpr(\"count(*) as row_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "190bf744-a89a-42b7-86eb-2df32b0abd2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c3068c-16a3-42a4-aa1e-ca139128d806",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inject random anomalies for 2026-01-29 data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "import random\n",
    "\n",
    "# Read the table and filter for the target date\n",
    "df = spark.table(\"mc.amadeus2.data_jan26\")\n",
    "df_target_date = df.filter(F.col(\"flight_leg_departure_date\") == \"2026-01-29\")\n",
    "\n",
    "# Add a random column to select 10% of rows\n",
    "df_with_random = df_target_date.withColumn(\"random_val\", F.rand(seed=42))\n",
    "\n",
    "# Select 10% of rows (random_val < 0.1)\n",
    "df_selected = df_with_random.filter(F.col(\"random_val\") < 0.1)\n",
    "\n",
    "# Add another random column to decide between high/low outlier (50/50 split)\n",
    "df_selected = df_selected.withColumn(\"outlier_type\", F.rand(seed=123))\n",
    "\n",
    "# Apply multipliers: if outlier_type < 0.5, use high multiplier (2.0-3.0), else low (0.3-0.5)\n",
    "df_selected = df_selected.withColumn(\n",
    "    \"multiplier\",\n",
    "    F.when(F.col(\"outlier_type\") < 0.5, \n",
    "           F.lit(2.0) + F.rand(seed=456) * F.lit(1.0))  # 2.0 to 3.0\n",
    "    .otherwise(\n",
    "           F.lit(0.3) + F.rand(seed=789) * F.lit(0.2))  # 0.3 to 0.5\n",
    ")\n",
    "\n",
    "# Calculate new seat values\n",
    "df_selected = df_selected.withColumn(\n",
    "    \"new_flight_leg_total_seats\",\n",
    "    (F.col(\"flight_leg_total_seats\") * F.col(\"multiplier\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "# Create a temporary view for the update\n",
    "df_updates = df_selected.select(\n",
    "    \"trip_origin_city\",\n",
    "    \"trip_destination_city\", \n",
    "    \"flight_leg_departure_date\",\n",
    "    \"flight_leg_origin_city\",\n",
    "    \"flight_leg_destination_city\",\n",
    "    \"new_flight_leg_total_seats\",\n",
    "    \"flight_leg_total_seats\",\n",
    "    \"multiplier\"\n",
    ")\n",
    "\n",
    "df_updates.createOrReplaceTempView(\"anomaly_updates\")\n",
    "\n",
    "print(f\"Total rows for 2026-01-29: {df_target_date.count()}\")\n",
    "print(f\"Rows selected for anomaly injection (10%): {df_updates.count()}\")\n",
    "print(f\"\\nSample of updates (showing original vs new seat counts):\")\n",
    "display(df_updates.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94541aeb-6d51-4d56-95b8-4f837c9ca244",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Apply updates to the data_jan26 table"
    }
   },
   "outputs": [],
   "source": [
    "# Save the updates to a temporary table\n",
    "df_updates.write.mode(\"overwrite\").saveAsTable(\"mc.amadeus2.anomaly_updates\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd8049e3-dbdd-40a6-9ecb-fbd9a56c6957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use SQL UPDATE with a correlated subquery to update matching rows\n",
    "# We'll update based on all the key columns plus use LIMIT 1 to handle duplicates\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO mc.amadeus2.data_jan26 AS target\n",
    "USING mc.amadeus2.temp_anomaly_updates AS updates\n",
    "ON target.trip_origin_city = updates.trip_origin_city \n",
    "   AND target.trip_destination_city = updates.trip_destination_city \n",
    "   AND target.flight_leg_departure_date = updates.flight_leg_departure_date \n",
    "   AND target.flight_leg_origin_city = updates.flight_leg_origin_city \n",
    "   AND target.flight_leg_destination_city = updates.flight_leg_destination_city\n",
    "   AND target.flight_leg_total_seats = updates.flight_leg_total_seats\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  target.flight_leg_total_seats = updates.new_flight_leg_total_seats\n",
    "\"\"\")\n",
    "\n",
    "# Clean up temp table\n",
    "#spark.sql(\"DROP TABLE IF EXISTS mc.amadeus2.temp_anomaly_updates\")\n",
    "\n",
    "print(\"âœ“ Anomalies successfully injected into mc.amadeus2.data_jan26\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7868052644209910,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "data prep",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
